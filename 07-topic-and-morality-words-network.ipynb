{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58708570-158c-4c78-bcbe-130c2aa6d25d",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17245ee-8945-4d57-9f4f-8f8469ddff3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/10 14:42:58 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"network\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "668c0e63-0e55-401a-acfd-668a31a45009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import functions as F\n",
    "import itertools\n",
    "from sparknlp.base import Finisher\n",
    "from pyspark.sql.functions import col, least, greatest, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efebc8fe-1158-431d-aaf8-f2820c72f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"../data/cleaned_moral_scores.csv\", header= True).select([\"id\", \"cleaned_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acaa6a04-403e-4fa4-9235-5cf43c93842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   id|        cleaned_text|\n",
      "+-----+--------------------+\n",
      "|hk5r2|i had an appointm...|\n",
      "|iqimz|i created this si...|\n",
      "|pfzt5|hello everyone  i...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ac57c-6d3b-47f6-8840-adab57cc857b",
   "metadata": {},
   "source": [
    "## Define words to include in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30443f60-6c7a-4d03-87a3-016a1c906b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_moral = [\n",
    "    \"absurd\", \"absurdity\", \"absurdities\", \"accusation\", \"accusations\", \"accusative\", \"accuse\",\n",
    "    \"accuses\", \"accusing\", \"admirable\", \"admonish\", \"admonished\", \"admonishing\", \"admonishes\",\n",
    "    \"admonishment\", \"adulterate\", \"adulterated\", \"adulterating\", \"adulterates\", \"adulteration\",\n",
    "    \"adulterer\", \"adulterers\", \"adulteress\", \"adulteresses\", \"adulteries\", \"adulterous\",\n",
    "    \"adultery\", \"amoral\", \"amorality\", \"arrogant\", \"betray\", \"betrayed\", \"betraying\",\n",
    "    \"betrays\", \"betrayal\", \"betrayer\", \"bigot\", \"bigots\", \"bigoted\", \"bigotry\", \"blame\",\n",
    "    \"blames\", \"blamed\", \"blaming\", \"brave\", \"bravely\", \"braver\", \"bravest\", \"buffoon\",\n",
    "    \"buffoons\", \"buffoonish\", \"careless\", \"carelessness\", \"carpetbag\", \"carpetbags\",\n",
    "    \"censure\", \"censured\", \"censures\", \"censuring\", \"chastise\", \"chastised\", \"chastises\",\n",
    "    \"chastising\", \"chauvinism\", \"chauvinist\", \"chauvinistic\", \"cheat\", \"cheats\", \"cheated\",\n",
    "    \"cheating\", \"commend\", \"commended\", \"commends\", \"commending\", \"competence\",\n",
    "    \"competent\", \"conceit\", \"conceited\", \"connive\", \"connived\", \"connives\", \"conniving\",\n",
    "    \"conscience\", \"contemptible\", \"contemptibly\", \"corrupt\", \"corrupted\", \"corrupting\",\n",
    "    \"corruption\", \"courage\", \"courageous\", \"craven\", \"criminal\", \"criminals\", \"crook\",\n",
    "    \"crooks\", \"cruel\", \"crueler\", \"cruelest\", \"crueller\", \"cruellest\", \"cruelly\",\n",
    "    \"cruelties\", \"cruelty\", \"debauch\", \"debauched\", \"debauches\", \"debauching\", \"decadence\",\n",
    "    \"decadent\", \"deceive\", \"deceived\", \"deceives\", \"deceiving\", \"decency\", \"decent\",\n",
    "    \"decently\", \"deceptive\", \"deceptively\", \"delinquent\", \"delinquency\", \"deprave\",\n",
    "    \"depraved\", \"depraves\", \"depraving\", \"deserve\", \"deserved\", \"deserves\", \"deserving\",\n",
    "    \"despicable\", \"deviant\", \"deviants\", \"dignified\", \"dignity\", \"disapprove\",\n",
    "    \"disapproved\", \"disapproves\", \"disapproving\", \"disgrace\", \"disgraced\", \"disgraces\",\n",
    "    \"disgracing\", \"dishonest\", \"dishonesty\", \"dishonor\", \"dishonored\", \"dishonorable\",\n",
    "    \"dishonourable\", \"disloyal\", \"disrespect\", \"disrespected\", \"disrespecting\",\n",
    "    \"disrespectful\", \"diss\", \"dissed\", \"dissing\", \"dumb\", \"dutiful\", \"duty\", \"elitism\",\n",
    "    \"elitist\", \"elitists\", \"equality\", \"equitable\", \"ethic\", \"ethical\", \"ethics\", \"evil\",\n",
    "    \"evildoer\", \"evildoers\", \"excuse\", \"excuses\", \"excused\", \"excusing\", \"fairness\",\n",
    "    \"faithful\", \"faithless\", \"fake\", \"fakes\", \"faking\", \"fatass\", \"fatso\", \"fatties\",\n",
    "    \"forgive\", \"forgiven\", \"forgives\", \"forgiving\", \"foul\", \"fouled\", \"fouling\", \"fraud\",\n",
    "    \"frauds\", \"fraudulent\", \"generosity\", \"generous\", \"glutton\", \"gluttony\", \"godless\",\n",
    "    \"godlessness\", \"grandiose\", \"greed\", \"greedy\", \"hateful\", \"haters\", \"heathen\",\n",
    "    \"heathens\", \"hero\", \"heroes\", \"heroic\", \"heroine\", \"heroines\", \"hideous\", \"hideously\",\n",
    "    \"homily\", \"fault\", \"faults\", \"faulted\", \"faulting\", \"honest\", \"honesty\", \"honor\",\n",
    "    \"honored\", \"honoring\", \"honorable\", \"honour\", \"horrid\", \"horridly\", \"humane\",\n",
    "    \"humanitarian\", \"hypocrisy\", \"hypocrite\", \"hypocrites\", \"ideal\", \"ideals\", \"ideologue\",\n",
    "    \"ignoble\", \"ignorant\", \"immodest\", \"immoral\", \"immorality\", \"inappropriate\",\n",
    "    \"inconsiderate\", \"incorruptible\", \"indecency\", \"indecent\", \"indignantly\", \"inequity\",\n",
    "    \"infallible\", \"infidel\", \"infidels\", \"infidelity\", \"inhumane\", \"iniquity\", \"injustice\",\n",
    "    \"innocence\", \"innocent\", \"innocently\", \"irresponsible\", \"judge\", \"judged\", \"judges\",\n",
    "    \"judging\", \"judgy\", \"justice\", \"justness\", \"kosher\", \"laughingstock\", \"lawless\",\n",
    "    \"lawlessness\", \"lazier\", \"laziest\", \"laziness\", \"lazy\", \"lecherous\", \"lewd\", \"liar\",\n",
    "    \"liars\", \"lousy\", \"loyal\", \"magnanimity\", \"magnanimous\", \"mansplain\", \"misbehave\",\n",
    "    \"misbehaved\", \"misbehaving\", \"misconduct\", \"miser\", \"miserly\", \"misogynist\",\n",
    "    \"misogynistic\", \"mistreat\", \"mistreated\", \"mistreating\", \"misuse\", \"misused\",\n",
    "    \"misuses\", \"misusing\", \"molest\", \"molested\", \"molesting\", \"moral\", \"morality\",\n",
    "    \"nefarious\", \"nerd\", \"nerds\", \"nerdy\", \"noble\", \"obstinate\", \"offensive\",\n",
    "    \"opinionated\", \"outlaw\", \"outlawed\", \"outlawing\", \"outrageous\", \"overbearing\",\n",
    "    \"overconfident\", \"pariah\", \"patriot\", \"patriots\", \"pedophile\", \"penance\", \"penitent\",\n",
    "    \"perv\", \"pervert\", \"perverted\", \"perverts\", \"pervy\", \"pettier\", \"pettiest\", \"pettily\",\n",
    "    \"pettiness\", \"petty\", \"phony\", \"pitiful\", \"pitifully\", \"plagiarize\", \"prejudice\",\n",
    "    \"principled\", \"promiscuity\", \"promiscuous\", \"prude\", \"prudish\", \"psycho\", \"puny\",\n",
    "    \"pussies\", \"racist\", \"rapist\", \"rectitude\", \"redneck\", \"reprehensible\", \"repulsive\",\n",
    "    \"revolting\", \"revoltingly\", \"ridicule\", \"ridiculous\", \"ridiculously\", \"righteous\",\n",
    "    \"righteously\", \"ruthless\", \"scandal\", \"scandals\", \"scruples\", \"scrupulous\", \"scum\",\n",
    "    \"selfish\", \"selflessness\", \"sexism\", \"sexist\", \"shame\", \"shamed\", \"shaming\", \"sin\",\n",
    "    \"sincere\", \"sincerity\", \"sinful\", \"sinfully\", \"sinister\", \"sinned\", \"sinner\", \"sinners\",\n",
    "    \"sins\", \"sissies\", \"sissy\", \"skank\", \"slander\", \"slandered\", \"slandering\", \"slimy\",\n",
    "    \"slothful\", \"slut\", \"sluts\", \"slutty\", \"smug\", \"sneakily\", \"sneaky\", \"snide\",\n",
    "    \"snidely\", \"snob\", \"snobs\", \"spineless\", \"thief\", \"thieves\", \"traitor\", \"transgress\",\n",
    "    \"treacherous\", \"treason\", \"trustworthy\", \"trusty\", \"truthful\", \"truthfully\",\n",
    "    \"unacceptable\", \"unethical\", \"unfair\", \"unfaithful\", \"ungodly\", \"ungracious\", \"unjust\",\n",
    "    \"unloyal\", \"unpatriotic\", \"unprincipled\", \"unqualified\", \"unreasonable\", \"unsavory\",\n",
    "    \"unscrupulous\", \"unselfish\", \"untrustworthy\", \"unvirtuous\", \"unworthy\", \"upstanding\",\n",
    "    \"useful\", \"useless\", \"vain\", \"vainly\", \"vanity\", \"vengeance\", \"vile\", \"vilify\",\n",
    "    \"vindicate\", \"virtue\", \"virtuous\", \"wanton\", \"wicked\", \"worthless\", \"worthwhile\",\n",
    "    \"worthy\", \"wrong\", \"wrongdoing\", \"wronged\", \"wrongful\", \"wrongly\", \"zealot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907590f3-2b75-44f6-98c8-bc0dd8e302ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_morality = [\n",
    "    \"respect\", \"mistakes\", \"admit\", \"abuse\", \"responsibility\", \"lie\", \n",
    "    \"prove\", \"truth\", \"society\", \"behavior\", \"anger\", \"human\", \n",
    "    \"acknowledge\", \"belief\", \"treat\", \"angry\", \"god\", \"act\", \n",
    "    \"standard\", \"boundaries\", \n",
    "    \"character\", \"stupid\", \"horrible\", \"opinion\", \"accept\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3e4738-5158-4ad7-b608-c38ff8a168c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic0 = [\n",
    "    \"therapy\", \"emotion\", \"relationship\", \"feeling\", \"therapist\", \"child\", \n",
    "    \"emotional\", \"family\", \"depression\", \"toxic\", \"call\", \"mom\", \"god\", \n",
    "    \"response\", \"sad\", \"angry\", \"parent\", \"voice\", \"anger\", \"mother\"\n",
    "]\n",
    "\n",
    "topic1 = [\n",
    "    \"book\", \"game\", \"video\", \"read\", \"value\", \"youtube\", \"purpose\", \n",
    "    \"opinion\", \"play\", \"waste\", \"teach\", \"boundaries\", \"development\", \n",
    "    \"personal\", \"character\", \"meaningful\", \"knowledgeable\", \"information\", \n",
    "    \"trouble\", \"productive\"\n",
    "]\n",
    "\n",
    "topic2 = [\n",
    "    \"woman\", \"man\", \"social\", \"media\", \"sex\", \"porn\", \"anxiety\", \"date\", \n",
    "    \"relationship\", \"partner\", \"addiction\", \"drug\", \"anxious\", \"dude\", \n",
    "    \"male\", \"guy\", \"instagram\", \"account\", \"sick\", \"doctor\"\n",
    "]\n",
    "\n",
    "topic3 = [\n",
    "    \"skill\", \"interest\", \"activity\", \"hobbies\", \"practice\", \"language\", \n",
    "    \"content\", \"hobby\", \"specific\", \"music\", \"internet\", \"attention\", \n",
    "    \"online\", \"movie\", \"learn\", \"project\", \"community\", \"sport\", \"area\", \n",
    "    \"tv\"\n",
    "]\n",
    "\n",
    "topic4 = [\n",
    "    \"fear\", \"mind\", \"moment\", \"happiness\", \"journey\", \"success\", \"mindset\", \n",
    "    \"failure\", \"belief\", \"present\", \"future\", \"true\", \"reality\", \"happy\", \n",
    "    \"power\", \"process\", \"feeling\", \"challenge\", \"desire\", \"truth\"\n",
    "]\n",
    "\n",
    "topic5 = [\n",
    "    \"pain\", \"choice\", \"decision\", \"shit\", \"worth\", \"trust\", \"respect\", \n",
    "    \"fuck\", \"mistakes\", \"proud\", \"nobody\", \"treat\", \"environment\", \"suck\", \n",
    "    \"pressure\", \"tough\", \"excuse\", \"regret\", \"wrong\", \"move\"\n",
    "]\n",
    "\n",
    "topic6 = [\n",
    "    \"weight\", \"food\", \"body\", \"gym\", \"exercise\", \"sleep\", \"bed\", \"drink\", \n",
    "    \"task\", \"list\", \"routine\", \"healthy\", \"wake\", \"water\", \"energy\", \n",
    "    \"health\", \"diet\", \"eat\", \"cold\", \"smoke\"\n",
    "]\n",
    "\n",
    "topic7 = [\n",
    "    \"girl\", \"guy\", \"confidence\", \"conversation\", \"talk\", \"nice\", \n",
    "    \"confident\", \"friend\", \"group\", \"personality\", \"comfortable\", \"weird\", \n",
    "    \"fun\", \"meet\", \"comfort\", \"hair\", \"kinda\", \"attractive\", \"face\", \"club\"\n",
    "]\n",
    "\n",
    "topic8 = [\n",
    "    \"job\", \"school\", \"money\", \"college\", \"class\", \"career\", \"high\", \"home\", \n",
    "    \"parent\", \"business\", \"car\", \"degree\", \"study\", \"house\", \"kid\", \n",
    "    \"company\", \"university\", \"family\", \"student\", \"country\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519fe038-e41d-4563-907d-6750fba6da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_keep = (liwc_moral + related_morality + topic0 + topic1 + topic2 + topic3 + topic4 + \n",
    "              topic5 + topic6 + topic7 + topic8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82034ce-65b0-4946-beaa-2f4e1dff6d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d428c58-86d2-45b8-ab17-dc6dd81eda23",
   "metadata": {},
   "source": [
    "## Define stopwords to facilitate further preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "858503ea-d38c-4b0d-af16-1a78339c03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "english = [\n",
    "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \n",
    "    \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\", \"cannot\", \"could\", \"did\", \n",
    "    \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \n",
    "    \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"it\", \n",
    "    \"its\", \"itself\", \"let\", \"me\", \"more\", \"most\", \"must\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \n",
    "    \"once\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"some\", \"such\", \n",
    "    \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \n",
    "    \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"were\", \"what\", \"when\", \"where\", \"which\", \n",
    "    \"while\", \"who\", \"whom\", \"why\", \"with\", \"would\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"will\", \"ll\", \n",
    "    \"re\", \"ve\", \"d\", \"s\", \"m\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \n",
    "    \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"many\", \"us\", \"ok\", \"hows\", \"ive\", \"ill\", \"im\", \"cant\", \"topics\", \"topic\",\n",
    "    \"discuss\", \"thoughts\", \"yo\", \"thats\", \"whats\", \"lets\", \"nothing\", \"oh\", \"omg\", \n",
    "         \"things\", \"stuff\", \"yall\", \"haha\", \"yes\", \"no\", \"wo\", \"like\", 'good', \n",
    "         'work', 'got', 'going', 'dont', 'really', 'want', 'make', 'think', \n",
    "         'know', 'feel', 'people', 'life', \"getting\", \"lot\" \"great\", \"i\", \"me\", \n",
    "         \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "        \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \n",
    "        \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \n",
    "        \"they\", \"them\", \"their\", \"theirs\",\"themselves\", \"what\", \"which\", \"who\", \n",
    "        \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \n",
    "        \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \n",
    "        \"does\", \"did\", \"doing\", \"will\", \"would\", \"can\", \"could\", \"may\",\n",
    "        \"might\", \"shall\", \"ought\", \"about\", \"above\", \"across\", \"after\", \n",
    "        \"against\", \"along\", \"amid\", \"among\", \"around\", \"as\", \"at\", \"before\", \"behind\",\n",
    "        \"below\", \"beneath\", \"beside\", \"between\", \"beyond\", \"but\", \"by\", \n",
    "        \"considering\", \"despite\", \"down\", \"during\", \"except\", \"for\",\n",
    "        \"from\", \"in\", \"inside\", \"into\", \"like\", \"near\", \"next\", \"notwithstanding\",\n",
    "        \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"out\", \"outside\", \"over\", \"past\",\n",
    "        \"regarding\", \"round\", \"since\", \"than\", \"through\", \"throughout\", \"till\", \n",
    "        \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\", \"up\",\n",
    "        \"upon\", \"versus\", \"via\", \"with\", \"within\", \"without\", \"cant\", \"cannot\", \n",
    "        \"couldve\", \"couldnt\", \"didnt\", \"doesnt\", \"dont\", \"hadnt\", \"hasnt\", \n",
    "        \"havent\", \"hed\", \"hell\", \"hes\", \"howd\", \"howll\", \"hows\", \"id\", \"ill\", \n",
    "        \"im\", \"ive\", \"isnt\", \"itd\", \"itll\", \"its\", \"lets\", \"mightve\", \n",
    "        \"shant\", \"shed\", \"shell\", \"shes\", \n",
    "        \"thatll\", \"thats\", \"thered\", \"therell\", \"therere\", \"theres\", \"theyd\", \n",
    "        \"theyll\", \"theyre\", \"theyve\", \"wed\", \"well\", \"were\", \"weve\", \"werent\", \n",
    "        \"whatd\", \"whatll\", \"whatre\", \"whats\", \"whatve\", \"whend\", \"whenll\", \n",
    "        \"whens\", \"whered\", \"wherell\", \"wheres\", \"whichd\", \"whichll\", \"whichre\", \n",
    "        \"whichs\", \"whod\", \"wholl\", \"whore\", \"whos\", \"whove\", \"whyd\", \"whyll\", \n",
    "        \"whys\", \"wont\", \"wouldve\", \"wouldnt\", \"youd\", \"youll\", \"youre\", \"youve\",\n",
    "        \"f\", \"m\", \"because\", \"go\", \"lot\", \"get\", \"still\", \"way\", \"something\", \"much\",\n",
    "        \"thing\", \"someone\", \"person\", \"anything\", \"goes\", \"ok\", \"so\", \"just\", \"mostly\", \n",
    "        \"put\", \"also\", \"lots\", \"yet\", \"ha\", \"etc\", \"even\", \"one\", \"bye\", \"take\", \"wasnt\"]\n",
    "\n",
    "time = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \n",
    "        \"sunday\", \"morning\", \"noon\", \"afternoon\", \"evening\", \"night\", \"midnight\",\n",
    "        \"dawn\", \"dusk\", \"week\", \"weekend\", \"weekends\",\"weekly\", \"today\", \n",
    "        \"yesterday\", \"tomorrow\", \"yesterdays\", \"todays\", \"mondays\", \"tuesdays\",\n",
    "        \"wednesdays\", \"thursdays\", \"fridays\", \"saturdays\", \"sundays\", \"day\",\n",
    "        \"everyday\", \"daily\", \"workday\", 'time', 'month', 'year', 'pm', 'am', \"ago\",\n",
    "        \"year\", \"now\"]\n",
    "\n",
    "reddit = [\"welcome\", \"hi\", \"hello\", \"sub\", \"reddit\", \"thanks\", \"thank\", \"maybe\",\n",
    "          \"wo30\", \"mods\", \"mod\", \"moderators\", \"subreddit\", \"btw\", \"aw\", \"aww\", \n",
    "          \"aww\", \"hey\", \"hello\", \"join\", \"joined\", \"post\", \"rselfimprovement\", \"blah\"]\n",
    "\n",
    "topic_specific = [\"self\", \"improvement\", \"change\", \"action\",\n",
    "    'change', 'start', 'goal', 'habit', 'new', 'old', \n",
    "    'care', 'world', 'everyone', 'love', 'u', 'right', 'mean', 'matter',\n",
    "    'best', 'step', 'focus', 'hard', 'small',\n",
    "    'bad', 'help', 'time', 'problem', 'issue', 'advice',\n",
    "    'bit', 'experience', 'different',\n",
    "    'point', 'situation', 'negative', 'control', 'positive',\n",
    "    'use', 'question', 'idea', 'amp', 'medium', 'hour', 'day', 'minute',\n",
    "    'aaaaloot', \"selfimprovement\", \"_\", \"ampxb\"]\n",
    "\n",
    "stopwords = english + time + reddit + topic_specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e988b-e351-4391-a885-cf1ce524d034",
   "metadata": {},
   "source": [
    "## Create network from corpus, only keeping defined words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bf40d-c660-433c-b6ca-f9e5a0f796fb",
   "metadata": {},
   "source": [
    "### Standard preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acdea17a-b595-4fb1-8ac2-3f62e11e88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "     .setInputCol(\"cleaned_text\")\\\n",
    "     .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "            .setInputCols(['document'])\\\n",
    "            .setOutputCol('tokenized')\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['tokenized']) \\\n",
    "     .setOutputCol('normalized')\n",
    "\n",
    "lemmatizer = LemmatizerModel.load(\"../models/lemma_ewt_en_3.4.3_3.0_1651416655397/\")\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"lemmatized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemmatized']) \\\n",
    "     .setOutputCol('words') \\\n",
    "     .setStopWords(stopwords)\n",
    "\n",
    "finisher = Finisher().setInputCols(['words'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96bbc07f-9849-4383-aebe-7a3b56deb6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|   id|        cleaned_text|      finished_words|\n",
      "+-----+--------------------+--------------------+\n",
      "|hk5r2|i had an appointm...|[appointment, den...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "my_pipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          tokenizer,\n",
    "          normalizer,\n",
    "          lemmatizer,\n",
    "          stopwords_cleaner,\n",
    "          finisher\n",
    "      ])\n",
    "pipelineModel = my_pipeline.fit(data)\n",
    "processed_data = pipelineModel.transform(data)\n",
    "processed_data.persist()\n",
    "processed_data.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba773b9-c91a-47eb-a76a-983a652a69b4",
   "metadata": {},
   "source": [
    "### Keep only desired words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4702eb0d-b05b-4b5b-b796-62e1178fdc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|   id|        cleaned_text|      finished_words|      filtered_words|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|hk5r2|i had an appointm...|[appointment, den...|       [call, smoke]|\n",
      "|iqimz|i created this si...|[create, site, se...|[forgive, useful,...|\n",
      "|pfzt5|hello everyone  i...|[recently, made, ...|[information, min...|\n",
      "|pk714|i grew up with bo...|[grow, body, dysm...|[body, social, de...|\n",
      "|q0q8x|i have to ask whe...|[content, never, ...|[content, process...|\n",
      "|q412v|nothing but oppor...|[butt, opportunit...|[feeling, mind, p...|\n",
      "|q5mqk|im getting out of...|[comfort, zone, t...|[comfort, club, c...|\n",
      "|q70xe|hey everyone firs...|[first, learn, so...|[learn, social, t...|\n",
      "|q7mrn|facebook is great...|[facebook, great,...|[stupid, social, ...|\n",
      "|qcsyp|okay so im 18 yea...|[okay, male, semi...|[male, standard, ...|\n",
      "|qu825|well to give ever...|[give, everybody,...|[worthwhile, hous...|\n",
      "|qxco0|i hate adderall i...|[hate, adderall, ...|[sleep, exercise,...|\n",
      "|r89qc|im not sure if th...|[sure, place, but...|[play, game, play...|\n",
      "|ra0bn|to access your to...|[access, total, s...|[success, power, ...|\n",
      "|rbi6h|i beginning to th...|[begin, inferiori...|[shit, decision, ...|\n",
      "|rd166|ive been working ...|[working, horribl...|[horrible, high, ...|\n",
      "|rrhg8|ive tried every d...|[try, ever, butt,...|                  []|\n",
      "|rvjcf|context last seme...|[context, last, s...|[school, play, st...|\n",
      "|s0ruk|lately ive had th...|[lately, urge, ba...|[emotional, fear,...|\n",
      "|sa2de|its at about 1843...|[se, show, surpri...|  [true, learn, job]|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def filter_words(word_list):\n",
    "    return [word for word in word_list if word in words_keep]\n",
    "\n",
    "filter_words_udf = udf(filter_words, ArrayType(StringType()))\n",
    "\n",
    "filtered_df = processed_data.withColumn(\"filtered_words\", \n",
    "            filter_words_udf(processed_data[\"finished_words\"]))\n",
    "\n",
    "filtered_df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15b52a-8182-477e-9dcb-9b383feb8bed",
   "metadata": {},
   "source": [
    "### Create edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4f0252e-f520-436b-9c62-c46d84df197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edges(tokens):\n",
    "    return [list(pair) for pair in itertools.combinations(tokens, 2)]\n",
    "\n",
    "generate_edges_udf = udf(generate_edges, ArrayType(ArrayType(StringType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e3d1d62-c074-400e-b25d-746c3f81f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = filtered_df.withColumn(\"edges\", generate_edges_udf(F.col(\"filtered_words\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff0f10a4-b48f-402c-974c-a8a08cbbc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat_edges = df_edges.select(\n",
    "    F.col(\"id\"),\n",
    "    F.explode(F.col(\"edges\")).alias(\"edge\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18895ab9-7dde-40a6-b622-bdd3e6f58ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = df_flat_edges.select(\n",
    "    F.col(\"id\").alias(\"id_doc\"),\n",
    "    F.col(\"edge\")[0].alias(\"node1\"),\n",
    "    F.col(\"edge\")[1].alias(\"node2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63d85fe5-861b-45cd-a435-226e4257ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = edges_df.withColumn(\"weight\", lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38399ec6-5961-4fac-9f42-6168b5723867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pairs: ensure node1 is always less than node2, so they can be always on the same order\n",
    "edges_df = edges_df.withColumn(\"node1_norm\", least(col(\"node1\"), col(\"node2\"))) \\\n",
    "             .withColumn(\"node2_norm\", greatest(col(\"node1\"), col(\"node2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "824aa0d0-f681-4501-829a-cd700e6a9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = edges_df.groupBy(\"node1_norm\", \"node2_norm\").sum(\"weight\") \\\n",
    "                        .withColumnRenamed(\"sum(weight)\", \"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58000f99-111d-43dd-b09f-59cfc1344e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=====================================================>  (19 + 1) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+\n",
      "|node1_norm|node2_norm|weight|\n",
      "+----------+----------+------+\n",
      "|      book|      read|116662|\n",
      "|       man|     woman| 85356|\n",
      "|     learn|      read| 57908|\n",
      "|      game|      play| 54228|\n",
      "|     media|    social| 49230|\n",
      "|      book|     learn| 43003|\n",
      "|      high|    school| 42261|\n",
      "|     learn|     skill| 41263|\n",
      "|       job|     money| 40559|\n",
      "|       job|     learn| 40473|\n",
      "+----------+----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "edges_df = edges_df.filter(F.col('node1_norm') != F.col('node2_norm'))\n",
    "edges_df.orderBy('weight', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a004a864-9739-4281-996b-313b6560342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "edges_df.write.mode(\"overwrite\").csv(\"edges_topics_morality_net\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc54c3-87f4-49ef-ae11-e9a586841553",
   "metadata": {},
   "source": [
    "### Create nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9201c13-6a9b-4c00-ab67-ab6e9f790433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "vertices_df = edges_df.select(F.col(\"node1_norm\").alias(\"node\")).union(edges_df.select(F.col(\"node2_norm\").alias(\"node\"))).distinct()\n",
    "vertices_df.write.mode(\"overwrite\").csv(\"nodes_topics_morality_net\", header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
