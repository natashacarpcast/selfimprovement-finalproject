{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759ed55c-4fa6-47c3-add7-4ab66bda7070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/10 14:04:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import functions as F\n",
    "from sparknlp.base import Finisher\n",
    "import itertools\n",
    "from pyspark.sql.functions import col, when, least, greatest, lit\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"network\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9a7e8b-d5ba-471f-9413-a60a48c024b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"../data/cleaned_moral_scores.csv\", header= True).select('id', 'cleaned_text', 'emo_pos', 'emo_neg', \n",
    "                                                                          'emo_anx','emo_anger','emo_sad', 'moral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5172af0-ce11-4a81-8d8e-63f0c4afea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+\n",
      "|   id|        cleaned_text|emo_pos|emo_neg|emo_anx|emo_anger|emo_sad|moral|\n",
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+\n",
      "|hk5r2|i had an appointm...|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|iqimz|i created this si...|   2.56|    0.0|    0.0|      0.0|    0.0| 1.71|\n",
      "|pfzt5|hello everyone  i...|   2.06|    0.0|    0.0|      0.0|    0.0| 0.52|\n",
      "|pk714|i grew up with bo...|   1.71|    1.2|   0.34|      0.0|   0.51| 0.68|\n",
      "|q0q8x|i have to ask whe...|   1.25|   1.61|   0.18|     0.18|    0.9| 0.18|\n",
      "|q412v|nothing but oppor...|   1.05|   3.16|    0.0|      0.0|   3.16|  0.0|\n",
      "|q5mqk|im getting out of...|   3.27|   1.96|   1.31|      0.0|    0.0|  0.0|\n",
      "|q70xe|hey everyone firs...|    0.0|   1.96|    0.0|      0.0|    0.0|  0.0|\n",
      "|q7mrn|facebook is great...|   0.96|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|qcsyp|okay so im 18 yea...|   0.74|   0.74|    0.0|      0.0|    0.0|  0.0|\n",
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74f582-3d7e-4cff-a929-a19ed5d61818",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b97dca-8358-4cf4-910b-48f9480fc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define stopwords\n",
    "english = [\n",
    "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \n",
    "    \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\", \"cannot\", \"could\", \"did\", \n",
    "    \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \n",
    "    \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"it\", \n",
    "    \"its\", \"itself\", \"let\", \"me\", \"more\", \"most\", \"must\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \n",
    "    \"once\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"some\", \"such\", \n",
    "    \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \n",
    "    \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"were\", \"what\", \"when\", \"where\", \"which\", \n",
    "    \"while\", \"who\", \"whom\", \"why\", \"with\", \"would\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"will\", \"ll\", \n",
    "    \"re\", \"ve\", \"d\", \"s\", \"m\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \n",
    "    \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"many\", \"us\", \"ok\", \"hows\", \"ive\", \"ill\", \"im\", \"cant\", \"topics\", \"topic\",\n",
    "    \"discuss\", \"thoughts\", \"yo\", \"thats\", \"whats\", \"lets\", \"nothing\", \"oh\", \"omg\", \n",
    "         \"things\", \"stuff\", \"yall\", \"haha\", \"yes\", \"no\", \"wo\", \"like\", 'good', \n",
    "         'work', 'got', 'going', 'dont', 'really', 'want', 'make', 'think', \n",
    "         'know', 'feel', 'people', 'life', \"getting\", \"lot\" \"great\", \"i\", \"me\", \n",
    "         \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "        \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \n",
    "        \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \n",
    "        \"they\", \"them\", \"their\", \"theirs\",\"themselves\", \"what\", \"which\", \"who\", \n",
    "        \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \n",
    "        \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \n",
    "        \"does\", \"did\", \"doing\", \"will\", \"would\", \"can\", \"could\", \"may\",\n",
    "        \"might\", \"shall\", \"ought\", \"about\", \"above\", \"across\", \"after\", \n",
    "        \"against\", \"along\", \"amid\", \"among\", \"around\", \"as\", \"at\", \"before\", \"behind\",\n",
    "        \"below\", \"beneath\", \"beside\", \"between\", \"beyond\", \"but\", \"by\", \n",
    "        \"considering\", \"despite\", \"down\", \"during\", \"except\", \"for\",\n",
    "        \"from\", \"in\", \"inside\", \"into\", \"like\", \"near\", \"next\", \"notwithstanding\",\n",
    "        \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"out\", \"outside\", \"over\", \"past\",\n",
    "        \"regarding\", \"round\", \"since\", \"than\", \"through\", \"throughout\", \"till\", \n",
    "        \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\", \"up\",\n",
    "        \"upon\", \"versus\", \"via\", \"with\", \"within\", \"without\", \"cant\", \"cannot\", \n",
    "        \"couldve\", \"couldnt\", \"didnt\", \"doesnt\", \"dont\", \"hadnt\", \"hasnt\", \n",
    "        \"havent\", \"hed\", \"hell\", \"hes\", \"howd\", \"howll\", \"hows\", \"id\", \"ill\", \n",
    "        \"im\", \"ive\", \"isnt\", \"itd\", \"itll\", \"its\", \"lets\", \"mightve\", \n",
    "        \"shant\", \"shed\", \"shell\", \"shes\", \n",
    "        \"thatll\", \"thats\", \"thered\", \"therell\", \"therere\", \"theres\", \"theyd\", \n",
    "        \"theyll\", \"theyre\", \"theyve\", \"wed\", \"well\", \"were\", \"weve\", \"werent\", \n",
    "        \"whatd\", \"whatll\", \"whatre\", \"whats\", \"whatve\", \"whend\", \"whenll\", \n",
    "        \"whens\", \"whered\", \"wherell\", \"wheres\", \"whichd\", \"whichll\", \"whichre\", \n",
    "        \"whichs\", \"whod\", \"wholl\", \"whore\", \"whos\", \"whove\", \"whyd\", \"whyll\", \n",
    "        \"whys\", \"wont\", \"wouldve\", \"wouldnt\", \"youd\", \"youll\", \"youre\", \"youve\",\n",
    "        \"f\", \"m\", \"because\", \"go\", \"lot\", \"get\", \"still\", \"way\", \"something\", \"much\",\n",
    "        \"thing\", \"someone\", \"person\", \"anything\", \"goes\", \"ok\", \"so\", \"just\", \"mostly\", \n",
    "        \"put\", \"also\", \"lots\", \"yet\", \"ha\", \"etc\", \"even\", \"one\", \"bye\", \"take\", \"wasnt\"]\n",
    "\n",
    "time = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \n",
    "        \"sunday\", \"morning\", \"noon\", \"afternoon\", \"evening\", \"night\", \"midnight\",\n",
    "        \"dawn\", \"dusk\", \"week\", \"weekend\", \"weekends\",\"weekly\", \"today\", \n",
    "        \"yesterday\", \"tomorrow\", \"yesterdays\", \"todays\", \"mondays\", \"tuesdays\",\n",
    "        \"wednesdays\", \"thursdays\", \"fridays\", \"saturdays\", \"sundays\", \"day\",\n",
    "        \"everyday\", \"daily\", \"workday\", 'time', 'month', 'year', 'pm', 'am', \"ago\",\n",
    "        \"year\", \"now\"]\n",
    "\n",
    "reddit = [\"welcome\", \"hi\", \"hello\", \"sub\", \"reddit\", \"thanks\", \"thank\", \"maybe\",\n",
    "          \"wo30\", \"mods\", \"mod\", \"moderators\", \"subreddit\", \"btw\", \"aw\", \"aww\", \n",
    "          \"aww\", \"hey\", \"hello\", \"join\", \"joined\", \"post\", \"rselfimprovement\", \"blah\"]\n",
    "\n",
    "topic_specific = [\"self\", \"improvement\", \"change\", \"action\",\n",
    "    'change', 'start', 'goal', 'habit', 'new', 'old', \n",
    "    'care', 'world', 'everyone', 'love', 'u', 'right', 'mean', 'matter',\n",
    "    'best', 'step', 'focus', 'hard', 'small',\n",
    "    'bad', 'help', 'time', 'problem', 'issue', 'advice',\n",
    "    'bit', 'experience', 'different',\n",
    "    'point', 'situation', 'negative', 'control', 'positive',\n",
    "    'use', 'question', 'idea', 'amp', 'medium', 'hour', 'day', 'minute',\n",
    "    'aaaaloot', \"selfimprovement\", \"_\", \"ampxb\"]\n",
    "\n",
    "stopwords = english + time + reddit + topic_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f1aa45-fdf9-4280-bf27-cb8448f3672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "     .setInputCol(\"cleaned_text\")\\\n",
    "     .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "            .setInputCols(['document'])\\\n",
    "            .setOutputCol('tokenized')\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['tokenized']) \\\n",
    "     .setOutputCol('normalized')\n",
    "\n",
    "lemmatizer = LemmatizerModel.load(\"../models/lemma_ewt_en_3.4.3_3.0_1651416655397/\")\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"lemmatized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemmatized']) \\\n",
    "     .setOutputCol('words') \\\n",
    "     .setStopWords(stopwords)\n",
    "\n",
    "finisher = Finisher().setInputCols(['words'])\n",
    "\n",
    "my_pipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          tokenizer,\n",
    "          normalizer,\n",
    "          lemmatizer,\n",
    "          stopwords_cleaner,\n",
    "          finisher\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb703ec-8d2a-4a77-8468-f35f30baae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/software/spark-3.3.2-el8-x86_64/jars/spark-core_2.12-3.3.2.jar) to field java.util.regex.Pattern.pattern\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+\n",
      "|   id|        cleaned_text|emo_pos|emo_neg|emo_anx|emo_anger|emo_sad|moral|      finished_words|\n",
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+\n",
      "|hk5r2|i had an appointm...|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|[appointment, den...|\n",
      "|iqimz|i created this si...|   2.56|    0.0|    0.0|      0.0|    0.0| 1.71|[create, site, se...|\n",
      "|pfzt5|hello everyone  i...|   2.06|    0.0|    0.0|      0.0|    0.0| 0.52|[recently, made, ...|\n",
      "|pk714|i grew up with bo...|   1.71|    1.2|   0.34|      0.0|   0.51| 0.68|[grow, body, dysm...|\n",
      "|q0q8x|i have to ask whe...|   1.25|   1.61|   0.18|     0.18|    0.9| 0.18|[content, never, ...|\n",
      "|q412v|nothing but oppor...|   1.05|   3.16|    0.0|      0.0|   3.16|  0.0|[butt, opportunit...|\n",
      "|q5mqk|im getting out of...|   3.27|   1.96|   1.31|      0.0|    0.0|  0.0|[comfort, zone, t...|\n",
      "|q70xe|hey everyone firs...|    0.0|   1.96|    0.0|      0.0|    0.0|  0.0|[first, learn, so...|\n",
      "|q7mrn|facebook is great...|   0.96|    0.0|    0.0|      0.0|    0.0|  0.0|[facebook, great,...|\n",
      "|qcsyp|okay so im 18 yea...|   0.74|   0.74|    0.0|      0.0|    0.0|  0.0|[okay, male, semi...|\n",
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipelineModel = my_pipeline.fit(data)\n",
    "processed_data = pipelineModel.transform(data)\n",
    "processed_data.persist()\n",
    "processed_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afcff1a3-f45e-4f58-9fab-307bdc3f3695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, cleaned_text: string, emo_pos: string, emo_neg: string, emo_anx: string, emo_anger: string, emo_sad: string, moral: string, finished_words: array<string>, tf_features: vector, tf_idf_features: vector]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply TF-IDF filtering\n",
    "tfizer = CountVectorizer(inputCol='finished_words', outputCol='tf_features', minDF=0.01, vocabSize=1000)\n",
    "tf_model = tfizer.fit(processed_data)\n",
    "tf_result = tf_model.transform(processed_data)\n",
    "vocabulary = tf_model.vocabulary\n",
    "\n",
    "\n",
    "idfizer = IDF(inputCol='tf_features', outputCol='tf_idf_features')\n",
    "idf_model = idfizer.fit(tf_result)\n",
    "tfidf_result = idf_model.transform(tf_result)\n",
    "\n",
    "processed_data.unpersist()\n",
    "tfidf_result.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94440fc3-8f0d-4c52-93de-18bfa4c5fb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   id|        cleaned_text|emo_pos|emo_neg|emo_anx|emo_anger|emo_sad|moral|      finished_words|         tf_features|     tf_idf_features|filtered_words_tfidf|\n",
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|hk5r2|i had an appointm...|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|[appointment, den...|(805,[13,37,44,77...|(805,[13,37,44,77...|[never, happen, s...|\n",
      "|iqimz|i created this si...|   2.56|    0.0|    0.0|      0.0|    0.0| 1.71|[create, site, se...|(805,[0,3,58,135,...|(805,[0,3,58,135,...|[find, hope, futu...|\n",
      "|pfzt5|hello everyone  i...|   2.06|    0.0|    0.0|      0.0|    0.0| 0.52|[recently, made, ...|(805,[6,9,11,19,2...|(805,[6,9,11,19,2...|[look, learn, kee...|\n",
      "|pk714|i grew up with bo...|   1.71|    1.2|   0.34|      0.0|   0.51| 0.68|[grow, body, dysm...|(805,[0,2,3,5,6,7...|(805,[0,2,3,5,6,7...|[need, find, see,...|\n",
      "|q0q8x|i have to ask whe...|   1.25|   1.61|   0.18|     0.18|    0.9| 0.18|[content, never, ...|(805,[0,1,6,7,10,...|(805,[0,1,6,7,10,...|[butt, try, look,...|\n",
      "|q412v|nothing but oppor...|   1.05|   3.16|    0.0|      0.0|   3.16|  0.0|[butt, opportunit...|(805,[0,3,16,30,3...|(805,[0,3,16,30,3...|[find, feeling, m...|\n",
      "|q5mqk|im getting out of...|   3.27|   1.96|   1.31|      0.0|    0.0|  0.0|[comfort, zone, t...|(805,[0,1,8,13,22...|(805,[0,1,8,13,22...|[try, give, never...|\n",
      "|q70xe|hey everyone firs...|    0.0|   1.96|    0.0|      0.0|    0.0|  0.0|[first, learn, so...|(805,[0,4,9,11,14...|(805,[0,4,9,11,14...|[say, learn, keep...|\n",
      "|q7mrn|facebook is great...|   0.96|    0.0|    0.0|      0.0|    0.0|  0.0|[facebook, great,...|(805,[0,11,27,29,...|(805,[0,11,27,29,...|[keep, social, gr...|\n",
      "|qcsyp|okay so im 18 yea...|   0.74|   0.74|    0.0|      0.0|    0.0|  0.0|[okay, male, semi...|(805,[8,53,80,82,...|(805,[8,53,80,82,...|[give, guy, famil...|\n",
      "|qu825|well to give ever...|    0.0|   1.57|    0.0|      0.0|   0.79| 0.79|[give, everybody,...|(805,[0,8,11,13,1...|(805,[0,8,11,13,1...|[give, keep, neve...|\n",
      "|qxco0|i hate adderall i...|    0.0|    0.6|    0.0|      0.6|    0.0|  0.0|[hate, adderall, ...|(805,[1,5,7,18,24...|(805,[1,5,7,18,24...|[try, see, ever, ...|\n",
      "|r89qc|im not sure if th...|   1.23|   0.62|    0.0|      0.0|    0.0|  0.0|[sure, place, but...|(805,[0,3,25,35,4...|(805,[0,3,25,35,4...|[find, live, happ...|\n",
      "|ra0bn|to access your to...|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|[access, total, s...|(805,[8,29,86,99,...|(805,[8,29,86,99,...|[give, great, hig...|\n",
      "|rbi6h|i beginning to th...|   2.58|   0.52|    0.0|     0.52|    0.0| 0.52|[begin, inferiori...|(805,[0,1,3,4,6,1...|(805,[0,1,3,4,6,1...|[butt, try, find,...|\n",
      "|rd166|ive been working ...|   1.18|    0.0|    0.0|      0.0|    0.0|  0.0|[working, horribl...|(805,[0,5,15,20,2...|(805,[0,5,15,20,2...|[see, back, job, ...|\n",
      "|rrhg8|ive tried every d...|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|[try, ever, butt,...|(805,[0,1,2,7,24,...|(805,[0,1,2,7,24,...|[try, need, ever,...|\n",
      "|rvjcf|context last seme...|   2.34|   0.43|    0.0|     0.43|    0.0| 0.21|[context, last, s...|(805,[0,1,2,3,7,1...|(805,[0,1,2,3,7,1...|[try, need, find,...|\n",
      "|s0ruk|lately ive had th...|   1.27|   1.27|   0.64|      0.0|    0.0|  0.0|[lately, urge, ba...|(805,[0,1,10,13,1...|(805,[0,1,10,13,1...|[try, come, never...|\n",
      "|sa2de|its at about 1843...|    1.2|   2.41|    0.0|     2.41|    0.0|  0.0|[se, show, surpri...|(805,[9,11,20,24,...|(805,[9,11,20,24,...|[learn, keep, job...|\n",
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, cleaned_text: string, emo_pos: string, emo_neg: string, emo_anx: string, emo_anger: string, emo_sad: string, moral: string, finished_words: array<string>, tf_features: vector, tf_idf_features: vector]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to filter words by their TF-IDF score\n",
    "# UDF to map indices to words using the vocabulary\n",
    "def filter_tfidf(features, threshold=1, vocabulary=None):\n",
    "    if features is not None:\n",
    "        # Filter based on TF-IDF score and map indices to actual words\n",
    "        return [vocabulary[features.indices[i]] for i in range(len(features.values)) if features.values[i] >= threshold]\n",
    "    return []\n",
    "\n",
    "# Register the UDF\n",
    "filter_udf = udf(lambda features: filter_tfidf(features, threshold=1, vocabulary=vocabulary), ArrayType(StringType()))\n",
    "\n",
    "# Apply the filtering function\n",
    "df_filtered_tfidf = tfidf_result.withColumn(\"filtered_words_tfidf\", filter_udf(\"tf_idf_features\"))\n",
    "\n",
    "df_filtered_tfidf.show()\n",
    "tfidf_result.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72af97fe",
   "metadata": {},
   "source": [
    "Generate pairs of words that co-occur on the same documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebc64a9-d01a-4d71-9f61-233f51d860d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edges(tokens):\n",
    "    return [list(pair) for pair in itertools.combinations(tokens, 2)]\n",
    "\n",
    "generate_edges_udf = udf(generate_edges, ArrayType(ArrayType(StringType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07456dc3-88e6-4bcc-a11c-bedda717d129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   id|        cleaned_text|emo_pos|emo_neg|emo_anx|emo_anger|emo_sad|moral|      finished_words|         tf_features|     tf_idf_features|filtered_words_tfidf|               edges|\n",
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|hk5r2|i had an appointm...|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|[appointment, den...|(805,[13,37,44,77...|(805,[13,37,44,77...|[never, happen, s...|[[never, happen],...|\n",
      "|iqimz|i created this si...|   2.56|    0.0|    0.0|      0.0|    0.0| 1.71|[create, site, se...|(805,[0,3,58,135,...|(805,[0,3,58,135,...|[find, hope, futu...|[[find, hope], [f...|\n",
      "|pfzt5|hello everyone  i...|   2.06|    0.0|    0.0|      0.0|    0.0| 0.52|[recently, made, ...|(805,[6,9,11,19,2...|(805,[6,9,11,19,2...|[look, learn, kee...|[[look, learn], [...|\n",
      "|pk714|i grew up with bo...|   1.71|    1.2|   0.34|      0.0|   0.51| 0.68|[grow, body, dysm...|(805,[0,2,3,5,6,7...|(805,[0,2,3,5,6,7...|[need, find, see,...|[[need, find], [n...|\n",
      "|q0q8x|i have to ask whe...|   1.25|   1.61|   0.18|     0.18|    0.9| 0.18|[content, never, ...|(805,[0,1,6,7,10,...|(805,[0,1,6,7,10,...|[butt, try, look,...|[[butt, try], [bu...|\n",
      "|q412v|nothing but oppor...|   1.05|   3.16|    0.0|      0.0|   3.16|  0.0|[butt, opportunit...|(805,[0,3,16,30,3...|(805,[0,3,16,30,3...|[find, feeling, m...|[[find, feeling],...|\n",
      "|q5mqk|im getting out of...|   3.27|   1.96|   1.31|      0.0|    0.0|  0.0|[comfort, zone, t...|(805,[0,1,8,13,22...|(805,[0,1,8,13,22...|[try, give, never...|[[try, give], [tr...|\n",
      "|q70xe|hey everyone firs...|    0.0|   1.96|    0.0|      0.0|    0.0|  0.0|[first, learn, so...|(805,[0,4,9,11,14...|(805,[0,4,9,11,14...|[say, learn, keep...|[[say, learn], [s...|\n",
      "|q7mrn|facebook is great...|   0.96|    0.0|    0.0|      0.0|    0.0|  0.0|[facebook, great,...|(805,[0,11,27,29,...|(805,[0,11,27,29,...|[keep, social, gr...|[[keep, social], ...|\n",
      "|qcsyp|okay so im 18 yea...|   0.74|   0.74|    0.0|      0.0|    0.0|  0.0|[okay, male, semi...|(805,[8,53,80,82,...|(805,[8,53,80,82,...|[give, guy, famil...|[[give, guy], [gi...|\n",
      "+-----+--------------------+-------+-------+-------+---------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_edges = df_filtered_tfidf.withColumn(\"edges\", generate_edges_udf(F.col(\"filtered_words_tfidf\")))\n",
    "df_edges.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb651e94-17ca-42ba-a308-3c4bc6a2e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+-------+-------+-------+---------+-------+-----+\n",
      "|   id|               edge|emo_pos|emo_neg|emo_anx|emo_anger|emo_sad|moral|\n",
      "+-----+-------------------+-------+-------+-------+---------+-------+-----+\n",
      "|hk5r2|    [never, happen]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|      [never, sure]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|      [never, last]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|       [never, two]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|      [never, call]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|[never, completely]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     [never, phone]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|    [never, forget]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     [never, smoke]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     [never, three]|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "+-----+-------------------+-------+-------+-------+---------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_explode = df_edges.select(\n",
    "    F.col(\"id\"),\n",
    "    F.explode(F.col(\"edges\")).alias(\"edge\"), F.col('emo_pos'),\n",
    "    F.col('emo_neg'), F.col('emo_anx'), F.col('emo_anger'), \n",
    "    F.col('emo_sad'), F.col('moral'))\n",
    "\n",
    "df_explode.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f0c92-acad-4cd5-8e33-37b126114bad",
   "metadata": {},
   "source": [
    "Create edges df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6614b78f-5540-4ebf-b093-035082e07a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = df_explode.select(\n",
    "    F.col(\"edge\")[0].alias(\"node1\"),\n",
    "    F.col(\"edge\")[1].alias(\"node2\"))\n",
    "\n",
    "edges_df = edges_df.withColumn(\"weight\", lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd948f7-73bd-4b19-b7f9-c136293489e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pairs: ensure node1 is always less than node2, so they can be always on the same order\n",
    "edges_df = edges_df.withColumn(\"node1_norm\", least(col(\"node1\"), col(\"node2\"))) \\\n",
    "             .withColumn(\"node2_norm\", greatest(col(\"node1\"), col(\"node2\"))) \\\n",
    "             .select('node1_norm', 'node2_norm', 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79442c2c-4891-4a28-a4e1-c7ee2e5977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = edges_df.groupBy(\"node1_norm\", \"node2_norm\").sum(\"weight\") \\\n",
    "                        .withColumnRenamed(\"sum(weight)\", \"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398cbd5-f47b-42d8-9a89-6b92f963dcef",
   "metadata": {},
   "source": [
    "Create nodes df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c21d634-83bf-4501-a44e-fd2b20ea74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------+-------+-------+---------+-------+-----+\n",
      "|   id|      node|emo_pos|emo_neg|emo_anx|emo_anger|emo_sad|moral|\n",
      "+-----+----------+-------+-------+-------+---------+-------+-----+\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|    happen|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|      sure|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|      last|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|       two|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|      call|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|completely|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     phone|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|    forget|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     smoke|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     never|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|hk5r2|     three|    0.0|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "+-----+----------+-------+-------+-------+---------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=====================================================>  (19 + 1) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+-------+-------+---------+-------+-----+\n",
      "|     id|      node|emo_pos|emo_neg|emo_anx|emo_anger|emo_sad|moral|\n",
      "+-------+----------+-------+-------+-------+---------+-------+-----+\n",
      "|1001497|     first|   0.53|   4.79|   2.13|     0.53|    1.6|  0.0|\n",
      "|1001497|    friend|   0.53|   4.79|   2.13|     0.53|    1.6|  0.0|\n",
      "|10018jv|   attract|   1.36|   1.82|    0.0|     1.82|    0.0| 0.45|\n",
      "|1001diz|      rule|   0.78|   3.13|   1.56|      0.0|   0.78|  0.0|\n",
      "|1001mlo|       two|    1.0|   1.34|   0.67|     0.33|    0.0| 0.67|\n",
      "|1001vtv|  continue|    2.1|    2.1|    0.0|      1.4|    0.0|  0.7|\n",
      "|10021rc|    effect|   1.01|   1.01|    0.0|      0.0|    0.0|  0.0|\n",
      "|10023zp|     crazy|   1.14|    0.0|    0.0|      0.0|    0.0| 0.57|\n",
      "|100268m|      club|   0.93|   2.78|   0.93|      0.0|   0.93|  0.0|\n",
      "|100268m|      room|   0.93|   2.78|   0.93|      0.0|   0.93|  0.0|\n",
      "|1002gvr|      true|   5.46|   1.09|    0.0|     0.55|    0.0| 1.09|\n",
      "|1002lda|     grade|   0.82|   2.87|    0.0|      0.0|   2.05| 0.41|\n",
      "|1002lda|  practice|   0.82|   2.87|    0.0|      0.0|   2.05| 0.41|\n",
      "|1002lda|       say|   0.82|   2.87|    0.0|      0.0|   2.05| 0.41|\n",
      "|1002smy|   history|   2.08|    0.0|    0.0|      0.0|    0.0|  0.3|\n",
      "|1002smy| recommend|   2.08|    0.0|    0.0|      0.0|    0.0|  0.3|\n",
      "|1002smy|   writing|   2.08|    0.0|    0.0|      0.0|    0.0|  0.3|\n",
      "|1002unz|      edit|   3.64|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|1002unz|       try|   3.64|    0.0|    0.0|      0.0|    0.0|  0.0|\n",
      "|1002wwt|absolutely|   1.16|   1.01|   0.24|     0.07|    0.1| 0.17|\n",
      "+-------+----------+-------+-------+-------+---------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nodes_df = df_explode.select(\n",
    "    F.col(\"id\"),\n",
    "    F.explode(F.col(\"edge\")).alias(\"node\"), F.col('emo_pos'),\n",
    "    F.col('emo_neg'), F.col('emo_anx'), F.col('emo_anger'), \n",
    "    F.col('emo_sad'), F.col('moral'))\n",
    "\n",
    "nodes_df.show(20) \n",
    "\n",
    "nodes_df_g = nodes_df.groupBy(\"id\", \"node\").agg(\n",
    "    F.first('emo_pos').alias('emo_pos'),\n",
    "    F.first('emo_neg').alias('emo_neg'),\n",
    "    F.first('emo_anx').alias('emo_anx'),\n",
    "    F.first('emo_anger').alias('emo_anger'),\n",
    "    F.first('emo_sad').alias('emo_sad'),\n",
    "    F.first('moral').alias('moral'))\n",
    "\n",
    "nodes_df_g.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b06cc1-ab84-43fb-8206-6bc551760e4e",
   "metadata": {},
   "source": [
    "Now, aggregate all words and average their emotions and morality scores for all documents in which they appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb4f9a38-1d6a-4d30-bb94-0c292bdb4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nodes = nodes_df_g.groupBy(\"node\").agg(\n",
    "    F.avg('emo_pos').alias('emo_pos'),\n",
    "    F.avg('emo_neg').alias('emo_neg'),\n",
    "    F.avg('emo_anx').alias('emo_anx'),\n",
    "    F.avg('emo_anger').alias('emo_anger'),\n",
    "    F.avg('emo_sad').alias('emo_sad'),\n",
    "    F.avg('moral').alias('moral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d754d5cf-e5a5-4246-bf59-8348840c0fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=====================================================>  (21 + 1) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|          node|           emo_pos|           emo_neg|            emo_anx|          emo_anger|            emo_sad|              moral|\n",
      "+--------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|       deserve|1.5325340000000003|          1.209236|0.22293399999999997| 0.2511029999999999|           0.215441| 1.3315949999999999|\n",
      "|         shame|1.0600765843385027|2.2937583764120237|  0.322152019911928|0.23373348650201034|0.27635075627034267|  1.323130384836301|\n",
      "|         blame|0.9059750435287285| 1.304735925710969|0.24512768427161924| 0.2946967498549042|0.22843441671503195| 1.3038073128264656|\n",
      "|         judge|1.0985308109304128| 1.176126783936276|0.38571412766898994|0.20677066047129108|0.15007854851200353| 1.3013209425821444|\n",
      "|         fault|0.9347229891404379|1.3532210565065341|0.24556046383213695| 0.2921166942757224|0.24308853303883673|  1.209361310509847|\n",
      "|          fake|1.4706276472853292|1.0421447824412784|  0.259441663457836| 0.2119618790912591|0.17734116288024648|  1.187489410858683|\n",
      "|         wrong|1.0491555110721884| 1.167614787939447|0.27805517327661705|0.23610033779557119| 0.1951404353809583| 1.1523404854247477|\n",
      "|        honest| 1.133891988034603|  1.04417252809443|0.26527771040504483|0.19167515563101298| 0.1702142452906459|  1.141148839841539|\n",
      "|          lazy|0.9232181938035594|1.1293909030982199| 0.2432788398154252|0.17834146341463408|0.21315491100856956| 1.1187778510217536|\n",
      "|        excuse|0.8754745653573728|1.0805086928525434|0.25410302640051513|0.18809272376046363|0.18104700579523506|  1.113979394719897|\n",
      "|        useful| 1.063150313747861|0.7952952082144895|0.21535082715345125|0.13790359383913292|0.13097547062179118| 1.0432558471192244|\n",
      "|        decent| 1.089428380411165|0.8887113488216615| 0.2226592010696975|  0.154843723884339|0.15855925121176667| 0.9678221627945848|\n",
      "|       respect|1.2976629844259326|0.9824339007605937| 0.2174003984063745|0.24172310756972112| 0.1417212966316552| 0.5819585295182904|\n",
      "|      mistakes|  1.08651376146789| 1.206936183082972| 0.2991753200927514|0.19392983163625363|0.20730920455691104| 0.5758342574856337|\n",
      "|         admit|1.0708411892675849|1.2331798404641043|0.28029369108049323| 0.2797860768672952| 0.1968219724437999| 0.5646899927483683|\n",
      "|         abuse|0.9784000766430347|1.4564725043111708|0.28691703391454304| 0.2789442421919908|0.23879095612186244| 0.5573922207319411|\n",
      "|responsibility|0.9924586225306995|1.0425774159103043|0.24983715963694608| 0.1875974372664175| 0.1744727709556861| 0.5422891083822743|\n",
      "|           lie| 1.033934733683421| 1.128795948987247|  0.254844336084021| 0.1991269692423106| 0.1881132783195799| 0.5280813953488372|\n",
      "|         prove| 1.085064029826552|0.9971518884746313| 0.2547025449829794|0.20985248824769004|0.16236018803695898| 0.5255600583562976|\n",
      "|         truth|1.0843247391037447| 1.071632903621854|0.24559954982606919|0.19370677307141398| 0.1786003683241252| 0.5171925516676897|\n",
      "|          hurt|1.0794338898483977| 2.223323738246019|0.29111047143862334| 0.3359092944412462| 0.2506844495618243| 0.5159380797031919|\n",
      "|       society|1.0513303370786515|0.9490685393258428| 0.2092258426966292|  0.184038202247191|0.16927977528089888| 0.5133831460674156|\n",
      "|      behavior|0.9597147772546181|1.1998587468308588| 0.2624655921767474| 0.2740420137631293|0.16327960883737774| 0.5055514306410721|\n",
      "|         anger|1.0227207523111255|2.9415078100095635| 0.3362304749760918| 1.6537918393369464| 0.3428912974179152| 0.5020672617150143|\n",
      "|         human|1.1652573183727204|1.0781909358741304| 0.2505560082743058|0.18839653983576754| 0.2034413589920391| 0.4925719300445057|\n",
      "|   acknowledge|1.1872616762635957|1.1736596289187464| 0.2911788227767114|0.22761036468330131|0.19772872680742162|0.48469289827255274|\n",
      "|        belief|1.0978669074026306|0.9670286303843176| 0.2594493164818158| 0.1819306164560227| 0.1405648697446479|  0.483658756770699|\n",
      "|         treat|1.2473290419662266|1.0707741180404613|0.23794766761411137|0.22228055509112185| 0.1799749205818425| 0.4810842668450093|\n",
      "|         angry|1.0126900354470263|2.7230143100958384| 0.3115307863988448| 1.4645214651437577| 0.3559642904030459|0.47498358933963497|\n",
      "|           god|1.3037262787482722|1.0962774915169033|0.23684303129320095|0.20605378911650116|0.21553600603242432|0.47242930752796275|\n",
      "|           act| 1.107698445382477|1.1567018428909714| 0.3003536497477608|0.25378204468238447| 0.1681287964583548|0.47026562339133143|\n",
      "|      standard|1.1029461161651501|0.8749895031490552|0.21906752974107765|0.16619489153254025| 0.1414363191042687| 0.4700367389783065|\n",
      "|    boundaries|1.1939894551845345|1.1450732278851787| 0.2582464362429213|0.26463386057410665|0.17176528021870735|0.46995118140988085|\n",
      "|     character| 1.239489965015651|0.9139679617013442| 0.2228374148407291| 0.1795783465291843|0.14243601546676485|  0.469587552936844|\n",
      "|        stupid|1.0060112951086433|1.3044539102134585|0.31247343735043553|0.30546855556619124|0.20919211256820142| 0.4602460036374078|\n",
      "|      horrible| 1.028774853247491|1.5077939784131793|0.33062677523196365|0.27838477561067976|0.26722401060405226| 0.4572202234425297|\n",
      "|       opinion|1.1300494918833315| 0.952545862478554|0.24413686155470507|0.21158044080770746|0.13707535964101886| 0.4539283357529367|\n",
      "|        accept|1.2199909657990966| 1.170043450204345|0.29298989029898903|0.21617552161755213| 0.1985325876532587| 0.4537423101742311|\n",
      "|         toxic|1.1287925017449394|1.2436105294645527|0.24871472729085653|0.27782331239405716| 0.2225924818027719| 0.4470345996609831|\n",
      "|         woman|1.1298240389821337|0.9462824851109911| 0.2251343394694099|0.21268915809420683|   0.14150311315647| 0.4449417975094749|\n",
      "|            op|1.1620971488912357|0.9785755015839492|0.20962935586061246|0.17931362196409714|0.18733157338965156| 0.4442154171066524|\n",
      "|      shouldnt|1.1015560859188547|1.1583398568019094| 0.2785766109785203| 0.2216410501193318|0.19999522673031025|0.44133556085918846|\n",
      "|      insecure|1.2605517013544763| 2.072746944169144|   1.19105550049554|0.27960521968946156|0.16937066402378592|0.44103072348860256|\n",
      "|         child|1.1223181856935802|1.1266578565947647| 0.2617452468241111|0.22104868275215278|0.19498934265495776| 0.4355963850285617|\n",
      "|         value| 1.223741377422534| 0.815937807949195|0.19484178254680834|0.15224734479360563|0.13778276579437207|0.43545439614584486|\n",
      "|         trust|1.1884794511511312|1.0658466917342835|0.30375090705191643|0.16363744310310707|0.19093607757767664|0.43336367834289874|\n",
      "| understanding|1.0697820499640178|0.9991724067029913|0.25950961241903975| 0.2039847846201296| 0.1633371029094274| 0.4328055926801685|\n",
      "|       clearly|1.0085381388845738|1.0975050489358396| 0.2767127543886903| 0.2279415876961317|0.17564237999067886| 0.4313002951685567|\n",
      "|        shitty|1.0603556581986144|1.2258922247882986|0.23045727482678988|0.25439722863741343| 0.2296104695919938| 0.4266081601231716|\n",
      "|        assume|0.9860194751217196|0.9824878280489252|0.25118869492934326|0.20893124332027072|0.14761073506709416|0.42566559790998687|\n",
      "+--------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_nodes.sort(final_nodes.moral.desc()).show(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
